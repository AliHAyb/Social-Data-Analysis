{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd4aef2",
   "metadata": {},
   "source": [
    "\n",
    "# <div style=\"text-align: center;\">\n",
    "  <span style=\"color: #505050; font-size: 30px;\">**Selenium Webscraping and Automation: Instagram Use Case**</span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c66b6",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4415b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports here\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1106f9bf",
   "metadata": {},
   "source": [
    "## Login Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your credentials\n",
    "username_str = 'your username'\n",
    "password_str = 'your password'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the path to chromedriver.exe (download and save on your computer)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#open the webpage\n",
    "driver.get(\"http://www.instagram.com\")\n",
    "\n",
    "#target username\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "\n",
    "#enter username and password\n",
    "username.clear()\n",
    "username.send_keys(username_str)\n",
    "password.clear()\n",
    "password.send_keys(password_str)\n",
    "\n",
    "#target the login button and click it\n",
    "button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "\n",
    "# #nadle NOT NOW\n",
    "not_now = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//div[contains(text(), \"Not now\")]'))).click()\n",
    "not_now2 = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dca140",
   "metadata": {},
   "source": [
    "## Access Any Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aafe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we sign in we can access any page on instagram\n",
    "# enter the name of any page\n",
    "company = 'linkedinlearning'\n",
    "driver.get(f\"http://www.instagram.com/{company}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1b90b",
   "metadata": {},
   "source": [
    "### Get Page Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2865ba9",
   "metadata": {},
   "source": [
    "### Get Page Main Information: Number of Posts, Number of Followers and Number of Following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the tag that contains the three element: number of posts, followers and following\n",
    "d = driver.find_elements(By.CLASS_NAME, 'html-span')\n",
    "\n",
    "# the find_elements return a list with the desirable content\n",
    "posts = d[0].text\n",
    "followers = d[1].text\n",
    "following = d[2].text\n",
    "\n",
    "# display results\n",
    "print(f\"Number of Followers: {followers}\")\n",
    "print(f\"Number of Following: {following}\")\n",
    "print(f\"Number of Posts: {posts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651b62d",
   "metadata": {},
   "source": [
    "### Scroll Accross The Page to Get More Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750790e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = set()  # Using a set to avoid duplicate URLs\n",
    "scrolls = 7  # Number of times you want to scroll\n",
    "for i in range(scrolls):\n",
    "    posts = driver.find_elements(By.CLASS_NAME, '_al3l')\n",
    "    for post in posts:\n",
    "        l = post.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "        urls.add(l)  # Adds only new URLs\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  # Scroll down to bottom\n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "# driver.quit()  # Close the browser when done\n",
    "\n",
    "urls = list(urls)  # Convert set back to list if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9831f1",
   "metadata": {},
   "source": [
    "## Final Script: Collecting All Data from Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0664f929",
   "metadata": {},
   "source": [
    "### Collecting post data and text cleaning with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store information\n",
    "likes = []\n",
    "dates = []\n",
    "captions = []\n",
    "tot_times = []\n",
    "tot_users = []\n",
    "tot_comments = []\n",
    "tot_num_likes = []\n",
    "hashtags = []\n",
    "\n",
    "# Strat looping on collected posts' urls \n",
    "for url in urls:\n",
    "    \n",
    "    # open the post page using its url\n",
    "    driver.get(url)\n",
    "    time.sleep(7.5)\n",
    "    \n",
    "    # get post like and store them in a list\n",
    "    like = driver.find_element(By.CLASS_NAME, 'html-span')\n",
    "    likes.append(like.text)\n",
    "    \n",
    "    # getting post date \n",
    "    date = driver.find_element(By.TAG_NAME, 'time').get_attribute('title')\n",
    "    dates.append(date)\n",
    "    \n",
    "    # getting post caption in the comments element as the first comment using its XPATH\n",
    "    cap = driver.find_element(By.XPATH, '/html/body/div[2]/div/div/div[2]/div/div/div[1]/div[1]/div[2]/section/main/div/div[1]/div/div[2]/div/div[2]/div/div[1]/div/div[2]/div/span/div/span')\n",
    "    captions.append(cap.text)\n",
    "    \n",
    "    # locate the mother tag that contains the comments\n",
    "    com = driver.find_elements(By.CLASS_NAME, \"x18hxmgj\")\n",
    "    comm = []\n",
    "    \n",
    "    # getting all comments and store them in a list \n",
    "    for x in com:\n",
    "        comm.append(x.text)\n",
    "        \n",
    "    # Regular expression pattern\n",
    "    pattern = r\"\\d+[hwdms]\" # time pattern, a number followed by one of any letter in the box \n",
    "    \n",
    "    # every iteration we empty the lists to store new data for each post\n",
    "    times = []\n",
    "    users = []\n",
    "    comments = []\n",
    "    num_likes = []\n",
    "    hashtag = []\n",
    "    for i, x in enumerate(comm):\n",
    "        if re.match(pattern, x):\n",
    "            times.append(x) # the element that match the pattern (time)\n",
    "            users.append(comm[i-1]) # user comes always before the time element\n",
    "            comments.append(comm[i+1]) # comments come after the time element\n",
    "            num_likes.append(comm[i+2]) # number of comment likes comes after the comment\n",
    "        hashtag = re.findall(r'#[\\w]+', x) # pattern that match the hashtag\n",
    "    hashtags.append(hashtag)\n",
    "    tot_times.append(times)\n",
    "    tot_users.append(users)\n",
    "    tot_comments.append(comments)\n",
    "    tot_num_likes.append(num_likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ace6d",
   "metadata": {},
   "source": [
    "### Further Preprocessing to get final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the first element because it's already collected \n",
    "for i, my_list in enumerate(tot_num_likes):\n",
    "    del my_list[0]\n",
    "    tot_num_likes[i] = ['0' if item == \"Reply\" else item for item in my_list] # replace Reply with 0\n",
    "    \n",
    "    '''\n",
    "    when the comment have 0 like, the 'Reply' word will always replace the number of likes \n",
    "    So we replace the word 'Reply' with 0 as 0 likes\n",
    "    \n",
    "    '''\n",
    "    \n",
    "result = []\n",
    "\n",
    "for sublist in tot_num_likes:\n",
    "    new_sublist = []\n",
    "    for item in sublist:\n",
    "        # Find all occurrences of one or more digits\n",
    "        numbers = re.findall(r'\\d+', item)\n",
    "        # Convert each found number to an integer and add to the new sublist\n",
    "        new_sublist.extend([int(num) for num in numbers])\n",
    "    # Add the new sublist to the result list\n",
    "    result.append(new_sublist)\n",
    "    \n",
    "# Delete the first element from each list\n",
    "for my_list in tot_comments:\n",
    "    del my_list[0]\n",
    "for my_list in tot_users:\n",
    "    del my_list[0]\n",
    "for my_list in tot_times:\n",
    "    del my_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3bd5ce",
   "metadata": {},
   "source": [
    "### Groupping All Together in a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd44911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Groupping all together with a dataframe\n",
    "dc = pd.DataFrame()\n",
    "\n",
    "dc['post likes'] = likes\n",
    "dc['post date'] = dates\n",
    "dc['post caption'] = captions\n",
    "dc['comments'] = tot_comments\n",
    "dc['time per comment'] = tot_times\n",
    "dc['user per comment'] = tot_users\n",
    "dc['likes per comment'] = tot_num_likes\n",
    "dc['num of comments'] = [len(com) for com in dc['comments']]\n",
    "\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.to_csv(\"skillshare.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f1bd6e",
   "metadata": {},
   "source": [
    "### Collecting Pages Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74332393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of companies names\n",
    "companies = ['udemy', 'coursera', 'datacamp', 'linkedinlearning', 'skillshare', 'udacity', 'edxonline']\n",
    "posts = []\n",
    "followers = []\n",
    "following = []\n",
    "\n",
    "# iterating on each company page url and collecting desirable data\n",
    "for company in companies:\n",
    "    driver.get(f\"http://www.instagram.com/{company}/\")\n",
    "    # d = driver.find_elements(By.CLASS_NAME, 'html-span')\n",
    "    # Wait for the elements to be present\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    d = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'html-span')))\n",
    "    posts.append(d[0].text)\n",
    "    followers.append(d[1].text)\n",
    "    following.append(d[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beea017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all together in a dataframe\n",
    "companies_df = pd.DataFrame()\n",
    "companies_df['name'] = companies\n",
    "companies_df['num of posts'] = posts\n",
    "companies_df['num of followers'] = followers\n",
    "companies_df['num of following'] = following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457fb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df.to_csv('companies_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300df766",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <span style=\"font-size: 3.5em; color: #505050;\">Thank You!</span>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
